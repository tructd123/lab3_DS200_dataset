{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d76f985",
   "metadata": {},
   "source": [
    "## 22521548 - Đỗ Tuấn Trực"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa8dc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reading CSV files with auto schema inference\n",
      "\n",
      "Orders Schema:\n",
      "root\n",
      " |-- Order_ID: string (nullable = true)\n",
      " |-- Customer_Trx_ID: string (nullable = true)\n",
      " |-- Order_Status: string (nullable = true)\n",
      " |-- Order_Purchase_Timestamp: timestamp (nullable = true)\n",
      " |-- Order_Approved_At: timestamp (nullable = true)\n",
      " |-- Order_Delivered_Carrier_Date: timestamp (nullable = true)\n",
      " |-- Order_Delivered_Customer_Date: timestamp (nullable = true)\n",
      " |-- Order_Estimated_Delivery_Date: timestamp (nullable = true)\n",
      "\n",
      "\n",
      "Customers Schema:\n",
      "root\n",
      " |-- Customer_Trx_ID: string (nullable = true)\n",
      " |-- Subscriber_ID: string (nullable = true)\n",
      " |-- Subscribe_Date: date (nullable = true)\n",
      " |-- First_Order_Date: date (nullable = true)\n",
      " |-- Customer_Postal_Code: string (nullable = true)\n",
      " |-- Customer_City: string (nullable = true)\n",
      " |-- Customer_Country: string (nullable = true)\n",
      " |-- Customer_Country_Code: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      "\n",
      "\n",
      "Order Items Schema:\n",
      "root\n",
      " |-- Order_ID: string (nullable = true)\n",
      " |-- Order_Item_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Seller_ID: string (nullable = true)\n",
      " |-- Shipping_Limit_Date: timestamp (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Freight_Value: double (nullable = true)\n",
      "\n",
      "\n",
      "Products Schema:\n",
      "root\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Product_Category_Name: string (nullable = true)\n",
      " |-- Product_Weight_Gr: integer (nullable = true)\n",
      " |-- Product_Length_Cm: integer (nullable = true)\n",
      " |-- Product_Height_Cm: integer (nullable = true)\n",
      " |-- Product_Width_Cm: integer (nullable = true)\n",
      "\n",
      "\n",
      "Reviews Schema:\n",
      "root\n",
      " |-- Review_ID: string (nullable = true)\n",
      " |-- Order_ID: string (nullable = true)\n",
      " |-- Review_Score: string (nullable = true)\n",
      " |-- Review_Comment_Title_En: string (nullable = true)\n",
      " |-- Review_Comment_Message_En: string (nullable = true)\n",
      " |-- Review_Creation_Date: string (nullable = true)\n",
      " |-- Review_Answer_Timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, avg, year, month, desc, col, when, isnan, isnull, to_timestamp\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fecom Inc E-commerce Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 1. Reading CSV files with schema inference and semicolon delimiter\n",
    "print(\"1. Reading CSV files with auto schema inference\")\n",
    "\n",
    "# Read Orders data\n",
    "orders_df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .csv(\"Orders.csv\")\n",
    "\n",
    "# Read Customer data\n",
    "customers_df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .csv(\"Customer_List.csv\")\n",
    "\n",
    "# Read Order Items data\n",
    "order_items_df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .csv(\"Order_Items.csv\")\n",
    "\n",
    "# Read Products data\n",
    "products_df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .csv(\"Products.csv\")\n",
    "\n",
    "# Read Order Reviews data\n",
    "reviews_df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .csv(\"Order_Reviews.csv\")\n",
    "\n",
    "# Show schemas to verify data types were correctly inferred\n",
    "print(\"\\nOrders Schema:\")\n",
    "orders_df.printSchema()\n",
    "\n",
    "print(\"\\nCustomers Schema:\")\n",
    "customers_df.printSchema()\n",
    "\n",
    "print(\"\\nOrder Items Schema:\")\n",
    "order_items_df.printSchema()\n",
    "\n",
    "print(\"\\nProducts Schema:\")\n",
    "products_df.printSchema()\n",
    "\n",
    "print(\"\\nReviews Schema:\")\n",
    "reviews_df.printSchema()\n",
    "\n",
    "# Convert timestamp strings to timestamp type for date operations\n",
    "orders_df = orders_df.withColumn(\n",
    "    \"Order_Purchase_Timestamp\", \n",
    "    to_timestamp(col(\"Order_Purchase_Timestamp\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6138f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Statistics on orders, customers, and sellers\n",
      "Total number of orders: 99441\n",
      "Total number of unique customers: 99442\n",
      "Total number of sellers: 3095\n"
     ]
    }
   ],
   "source": [
    "# 2. Count total orders, customers, and sellers\n",
    "print(\"\\n2. Statistics on orders, customers, and sellers\")\n",
    "\n",
    "# Count unique orders\n",
    "total_orders = orders_df.select(\"Order_ID\").distinct().count()\n",
    "print(f\"Total number of orders: {total_orders}\")\n",
    "\n",
    "# Count unique customers\n",
    "total_customers = customers_df.select(\"Customer_Trx_ID\").distinct().count()\n",
    "print(f\"Total number of unique customers: {total_customers}\")\n",
    "\n",
    "# Count unique sellers (assuming Seller_ID is in order_items_df)\n",
    "total_sellers = order_items_df.select(\"Seller_ID\").distinct().count()\n",
    "print(f\"Total number of sellers: {total_sellers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812bc349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Number of orders by country (descending order)\n",
      "+----------------+-----------+\n",
      "|Customer_Country|Order_Count|\n",
      "+----------------+-----------+\n",
      "|Germany         |41754      |\n",
      "|France          |12848      |\n",
      "|Netherlands     |11629      |\n",
      "|Belgium         |5464       |\n",
      "|Austria         |5043       |\n",
      "|Switzerland     |3640       |\n",
      "|United Kingdom  |3382       |\n",
      "|Poland          |2139       |\n",
      "|Czechia         |2034       |\n",
      "|Italy           |2025       |\n",
      "|Spain           |1651       |\n",
      "|Portugal        |1336       |\n",
      "|Sweden          |975        |\n",
      "|Denmark         |905        |\n",
      "|Serbia          |746        |\n",
      "|Norway          |716        |\n",
      "|Slovakia        |534        |\n",
      "|Slovenia        |495        |\n",
      "|Turkey          |485        |\n",
      "|Greece          |412        |\n",
      "|Lithuania       |351        |\n",
      "|Latvia          |280        |\n",
      "|Croatia         |254        |\n",
      "|Estonia         |148        |\n",
      "|Finland         |81         |\n",
      "|Luxembourg      |68         |\n",
      "|Andorra         |46         |\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Orders by country (descending order)\n",
    "print(\"\\n3. Number of orders by country (descending order)\")\n",
    "\n",
    "# Join orders with customers to get country information\n",
    "orders_with_customer = orders_df.join(\n",
    "    customers_df,\n",
    "    orders_df[\"Customer_Trx_ID\"] == customers_df[\"Customer_Trx_ID\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "orders_by_country = orders_with_customer.groupBy(\"Customer_Country\") \\\n",
    "    .agg(count(\"Order_ID\").alias(\"Order_Count\")) \\\n",
    "    .orderBy(desc(\"Order_Count\"))\n",
    "\n",
    "orders_by_country.show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5155688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Number of orders by year and month (year ascending, month descending)\n",
      "+----+-----+-----------+\n",
      "|Year|Month|Order_Count|\n",
      "+----+-----+-----------+\n",
      "|2022|   12|          1|\n",
      "|2022|   10|        324|\n",
      "|2022|    9|          4|\n",
      "|2023|   12|       5673|\n",
      "|2023|   11|       7544|\n",
      "|2023|   10|       4631|\n",
      "|2023|    9|       4285|\n",
      "|2023|    8|       4331|\n",
      "|2023|    7|       4026|\n",
      "|2023|    6|       3245|\n",
      "|2023|    5|       3700|\n",
      "|2023|    4|       2404|\n",
      "|2023|    3|       2682|\n",
      "|2023|    2|       1780|\n",
      "|2023|    1|        800|\n",
      "|2024|   10|          4|\n",
      "|2024|    9|         16|\n",
      "|2024|    8|       6512|\n",
      "|2024|    7|       6292|\n",
      "|2024|    6|       6167|\n",
      "|2024|    5|       6873|\n",
      "|2024|    4|       6939|\n",
      "|2024|    3|       7211|\n",
      "|2024|    2|       6728|\n",
      "|2024|    1|       7269|\n",
      "+----+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Orders by year and month (year ascending, month descending)\n",
    "print(\"\\n4. Number of orders by year and month (year ascending, month descending)\")\n",
    "\n",
    "# Extract year and month from order date\n",
    "orders_by_time = orders_df.withColumn(\"Year\", year(col(\"Order_Purchase_Timestamp\"))) \\\n",
    "    .withColumn(\"Month\", month(col(\"Order_Purchase_Timestamp\"))) \\\n",
    "    .groupBy(\"Year\", \"Month\") \\\n",
    "    .agg(count(\"Order_ID\").alias(\"Order_Count\")) \\\n",
    "    .orderBy(\"Year\", desc(\"Month\"))\n",
    "\n",
    "orders_by_time.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bc0da3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Review score statistics\n",
      "Average review score: 4.09\n",
      "\n",
      "Distribution of review scores:\n",
      "+------------------+------------+\n",
      "|Review_Score_Clean|Review_Count|\n",
      "+------------------+------------+\n",
      "|              NULL|          47|\n",
      "|               1.0|       11424|\n",
      "|               2.0|        3151|\n",
      "|               3.0|        8179|\n",
      "|               4.0|       19141|\n",
      "|               5.0|       57328|\n",
      "+------------------+------------+\n",
      "\n",
      "\n",
      "Number of NULL review scores: 47\n",
      "\n",
      "Percentage distribution of review scores:\n",
      "+------------------+-----+------------------+\n",
      "|Review_Score_Clean|Count|        Percentage|\n",
      "+------------------+-----+------------------+\n",
      "|               1.0|11424|11.513459580943934|\n",
      "|               2.0| 3151| 3.175674994708888|\n",
      "|               3.0| 8179| 8.243048486741985|\n",
      "|               4.0|19141|19.290890216985982|\n",
      "|               5.0|57328| 57.77692672061921|\n",
      "+------------------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Review score analysis\n",
    "print(\"\\n5. Review score statistics\")\n",
    "\n",
    "# Handle NULL values in Review_Score\n",
    "# First, convert Review_Score to numeric type\n",
    "reviews_df = reviews_df.withColumn(\"Review_Score\", col(\"Review_Score\").cast(\"double\"))\n",
    "\n",
    "clean_reviews_df = reviews_df.withColumn(\n",
    "    \"Review_Score_Clean\", \n",
    "    when(col(\"Review_Score\").isNull() | isnan(col(\"Review_Score\")), None).otherwise(col(\"Review_Score\"))\n",
    ")\n",
    "\n",
    "# Calculate average review score (excluding NULL values)\n",
    "avg_review_score = clean_reviews_df.agg(avg(\"Review_Score_Clean\").alias(\"Average_Review_Score\")).collect()[0][\"Average_Review_Score\"]\n",
    "print(f\"Average review score: {avg_review_score:.2f}\")\n",
    "\n",
    "# Count reviews by score\n",
    "reviews_by_score = clean_reviews_df.groupBy(\"Review_Score_Clean\") \\\n",
    "    .agg(count(\"*\").alias(\"Review_Count\")) \\\n",
    "    .orderBy(\"Review_Score_Clean\")\n",
    "\n",
    "print(\"\\nDistribution of review scores:\")\n",
    "reviews_by_score.show()\n",
    "\n",
    "# Count NULL and non-NULL values in Review_Score\n",
    "null_count = clean_reviews_df.filter(col(\"Review_Score_Clean\").isNull()).count()\n",
    "print(f\"\\nNumber of NULL review scores: {null_count}\")\n",
    "\n",
    "# Additional analysis: Show percentage distribution of review scores\n",
    "total_non_null_reviews = clean_reviews_df.filter(col(\"Review_Score_Clean\").isNotNull()).count()\n",
    "\n",
    "if total_non_null_reviews > 0:\n",
    "    percentage_by_score = clean_reviews_df.filter(col(\"Review_Score_Clean\").isNotNull()) \\\n",
    "        .groupBy(\"Review_Score_Clean\") \\\n",
    "        .agg(count(\"*\").alias(\"Count\")) \\\n",
    "        .withColumn(\"Percentage\", (col(\"Count\") * 100 / total_non_null_reviews)) \\\n",
    "        .orderBy(\"Review_Score_Clean\")\n",
    "\n",
    "    print(\"\\nPercentage distribution of review scores:\")\n",
    "    percentage_by_score.select(\"Review_Score_Clean\", \"Count\", \"Percentage\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "606d8e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10. Seller rankings by total revenue and number of orders\n",
      "\n",
      "Top 10 sellers by revenue:\n",
      "+--------------------+------------------+------------+-----------+----------------+\n",
      "|           Seller_ID|     Total_Revenue|Revenue_Rank|Order_Count|Order_Count_Rank|\n",
      "+--------------------+------------------+------------+-----------+----------------+\n",
      "|4869f7a5dfa277a7d...| 249640.6999999999|           1|       1156|              11|\n",
      "|7c67e1448b00f6e96...|239536.43999999994|           2|       1364|               8|\n",
      "|53243585a1d6dc264...|         235856.68|           3|        410|              38|\n",
      "|4a3ca9315b744ce9f...|235539.95999999967|           4|       1987|               2|\n",
      "|fa1c13f2614d7b5c4...|         204084.73|           5|        586|              21|\n",
      "|da8622b14eb17ae28...|185192.32000000015|           6|       1551|               5|\n",
      "|7e93a43ef30c4f03f...|182754.05000000005|           7|        340|              51|\n",
      "|1025f0e2d44d7041d...|         172860.69|           8|       1428|               7|\n",
      "|7a67c85e85bb2ce85...|162648.38000000012|           9|       1171|              10|\n",
      "|955fee9216a65b617...| 160602.6800000002|          10|       1499|               6|\n",
      "+--------------------+------------------+------------+-----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as spark_sum, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 10. Rank sellers by revenue and number of orders\n",
    "print(\"\\n10. Seller rankings by total revenue and number of orders\")\n",
    "\n",
    "# Calculate total revenue (price + freight value) for each seller\n",
    "seller_revenue = order_items_df.groupBy(\"Seller_ID\") \\\n",
    "    .agg(\n",
    "        spark_sum(col(\"Price\") + col(\"Freight_Value\")).alias(\"Total_Revenue\"),\n",
    "        count(\"Order_ID\").alias(\"Order_Count\")\n",
    "    )\n",
    "\n",
    "# Create window specifications for ranking\n",
    "window_spec_revenue = Window.orderBy(desc(\"Total_Revenue\"))\n",
    "window_spec_orders = Window.orderBy(desc(\"Order_Count\"))\n",
    "\n",
    "# Add ranking columns\n",
    "seller_rankings = seller_revenue \\\n",
    "    .withColumn(\"Revenue_Rank\", rank().over(window_spec_revenue)) \\\n",
    "    .withColumn(\"Order_Count_Rank\", rank().over(window_spec_orders)) \\\n",
    "    .orderBy(\"Revenue_Rank\")\n",
    "\n",
    "# Show top sellers by revenue\n",
    "print(\"\\nTop 10 sellers by revenue:\")\n",
    "seller_rankings.select(\n",
    "    \"Seller_ID\", \n",
    "    \"Total_Revenue\", \n",
    "    \"Revenue_Rank\", \n",
    "    \"Order_Count\", \n",
    "    \"Order_Count_Rank\"\n",
    ").show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd1c3c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sellers by order count:\n",
      "+--------------------+-----------+----------------+------------------+------------+\n",
      "|           Seller_ID|Order_Count|Order_Count_Rank|     Total_Revenue|Revenue_Rank|\n",
      "+--------------------+-----------+----------------+------------------+------------+\n",
      "|6560211a19b47992c...|       2033|               1|151265.76999999967|          11|\n",
      "|4a3ca9315b744ce9f...|       1987|               2|235539.95999999967|           4|\n",
      "|1f50f920176fa81da...|       1931|               3|142104.97999999986|          12|\n",
      "|cc419e0650a3c5ba7...|       1775|               4|129957.40999999989|          15|\n",
      "|da8622b14eb17ae28...|       1551|               5|185192.32000000015|           6|\n",
      "|955fee9216a65b617...|       1499|               6| 160602.6800000002|          10|\n",
      "|1025f0e2d44d7041d...|       1428|               7|         172860.69|           8|\n",
      "|7c67e1448b00f6e96...|       1364|               8|239536.43999999994|           2|\n",
      "|ea8482cd71df3c196...|       1203|               9| 54722.29000000009|          41|\n",
      "|7a67c85e85bb2ce85...|       1171|              10|162648.38000000012|           9|\n",
      "+--------------------+-----------+----------------+------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show top sellers by order count\n",
    "print(\"\\nTop 10 sellers by order count:\")\n",
    "seller_rankings.orderBy(\"Order_Count_Rank\").select(\n",
    "    \"Seller_ID\", \n",
    "    \"Order_Count\", \n",
    "    \"Order_Count_Rank\", \n",
    "    \"Total_Revenue\", \n",
    "    \"Revenue_Rank\"\n",
    ").show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a92d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
